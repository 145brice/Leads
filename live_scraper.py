#!/usr/bin/env python3
"""
LIVE SCRAPER DEMO - Pulls REAL data from county websites
"""
from flask import Flask, render_template, send_file, jsonify
from datetime import datetime
import requests
from bs4 import BeautifulSoup
import re
import io
from reportlab.lib.pagesizes import letter
from reportlab.lib import colors
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer
from reportlab.lib.units import inch

app = Flask(__name__)
app.secret_key = 'demo-secret-key'

# ==================== LIVE SCRAPERS ====================

def scrape_nashville_live():
    """Scrape REAL Nashville permit data from ArcGIS API"""
    permits = []
    try:
        print("üï∑Ô∏è  Scraping Nashville-Davidson County (LIVE DATA)...")
        
        # Nashville ArcGIS REST API - Building Permits Layer
        # This returns REAL permit data from Metro Nashville Codes Department
        url = "https://maps.nashville.gov/arcgis/rest/services/Codes/BuildingPermits/MapServer/0/query"
        params = {
            'where': '1=1',  # Get all records
            'outFields': '*',  # Get all fields
            'returnGeometry': 'false',  # We don't need map coordinates
            'resultRecordCount': '15',  # Limit to 15 recent permits
            'orderByFields': 'DATE_ACCEPTED DESC',  # Most recent first
            'f': 'json'  # JSON format
        }
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        }
        
        response = requests.get(url, params=params, headers=headers, timeout=15)
        if response.status_code == 200:
            data = response.json()
            
            if 'features' in data:
                for feature in data['features']:
                    attrs = feature.get('attributes', {})
                    
                    # Extract construction value (CONSTVAL)
                    const_val = attrs.get('CONSTVAL', 0)
                    if const_val is None:
                        const_val = 0
                    
                    # Convert timestamps to readable dates
                    date_accepted = attrs.get('DATE_ACCEPTED')
                    if date_accepted:
                        from datetime import datetime as dt
                        date_str = dt.fromtimestamp(date_accepted / 1000).strftime('%Y-%m-%d')
                    else:
                        date_str = 'N/A'
                    
                    permit = {
                        'county': 'Nashville-Davidson',
                        'permit_number': attrs.get('CASE_NUMBER', 'N/A'),
                        'address': attrs.get('LOCATION', 'N/A'),
                        'permit_type': attrs.get('CASE_TYPE_DESC', 'Building Permit'),
                        'sub_type': attrs.get('SUB_TYPE_DESC', ''),
                        'estimated_value': float(const_val),
                        'work_description': (attrs.get('SCOPE', 'Construction project') or 'Construction project')[:200],
                        'issue_date': date_str,
                        'status': attrs.get('STATUS_CODE', 'N/A'),
                        'building_sqft': attrs.get('BLDG_SQ_FT', 0) or 0,
                        'scraped_at': datetime.now().isoformat(),
                        'data_source': 'üåê LIVE - Nashville ArcGIS API'
                    }
                    permits.append(permit)
                
                print(f"   ‚úÖ Found {len(permits)} REAL Nashville permits from Metro Codes")
            else:
                print(f"   ‚ö†Ô∏è  No features in Nashville response")
        else:
            print(f"   ‚ùå Nashville API returned {response.status_code}")
    except Exception as e:
        print(f"   ‚ùå Error scraping Nashville: {e}")
    
    return permits

def scrape_generic_county(county_name, search_terms):
    """
    Generic scraper - DEMO DATA ONLY
    
    ‚ö†Ô∏è  These counties (Rutherford, Wilson, Sumner) do NOT have public online 
    permit databases/APIs. Real scraping would require:
    - Direct access to county permit systems
    - PDF scraping from posted documents  
    - Or arrangements with county IT departments
    
    This function returns SAMPLE DATA for demonstration purposes.
    """
    permits = []
    try:
        print(f"üï∑Ô∏è  Searching {county_name} County (DEMO DATA - no public API)...")
        
        # For demo purposes, create sample data based on county
        sample_permits = {
            'Rutherford': [
                {
                    'county': 'Rutherford',
                    'permit_number': 'RT-2025-' + str(1000 + i),
                    'address': f'{100*i} Medical Center Pkwy, Murfreesboro, TN',
                    'permit_type': ['Commercial', 'Residential', 'Addition'][i % 3],
                    'estimated_value': [250000, 400000, 175000][i % 3],
                    'work_description': 'Building permit application',
                    'issue_date': '2025-11-18',
                    'data_source': '‚ö†Ô∏è  DEMO SAMPLE DATA (no public API)'
                } for i in range(3)
            ],
            'Wilson': [
                {
                    'county': 'Wilson',
                    'permit_number': 'WL-2025-' + str(2000 + i),
                    'address': f'{200*i} Main St, Lebanon, TN',
                    'permit_type': ['Retail', 'Office', 'Warehouse'][i % 3],
                    'estimated_value': [180000, 320000, 450000][i % 3],
                    'work_description': 'Construction permit',
                    'issue_date': '2025-11-17',
                    'data_source': '‚ö†Ô∏è  DEMO SAMPLE DATA (no public API)'
                } for i in range(3)
            ],
            'Sumner': [
                {
                    'county': 'Sumner',
                    'permit_number': 'SM-2025-' + str(3000 + i),
                    'address': f'{300*i} Station Camp Rd, Gallatin, TN',
                    'permit_type': ['Residential', 'Commercial', 'Industrial'][i % 3],
                    'estimated_value': [350000, 280000, 520000][i % 3],
                    'work_description': 'New construction permit',
                    'issue_date': '2025-11-16',
                    'data_source': '‚ö†Ô∏è  DEMO SAMPLE DATA (no public API)'
                } for i in range(3)
            ]
        }
        
        permits = sample_permits.get(county_name, [])
        print(f"   ‚ö†Ô∏è  Generated {len(permits)} sample {county_name} permits (DEMO DATA)")
        
    except Exception as e:
        print(f"   ‚ùå Error generating {county_name} samples: {e}")
    
    return permits

def scrape_all_counties_live():
    """Scrape all counties - real data where available"""
    all_permits = []
    
    print("\n" + "="*60)
    print("üåê LIVE SCRAPING SESSION")
    print("="*60)
    
    # Nashville - try real API
    nashville = scrape_nashville_live()
    all_permits.extend(nashville)
    
    # Other counties - will use sample data (you'd implement real scrapers)
    for county in ['Rutherford', 'Wilson', 'Sumner']:
        permits = scrape_generic_county(county, 'building permits')
        all_permits.extend(permits)
    
    print("="*60)
    print(f"üìä TOTAL PERMITS COLLECTED: {len(all_permits)}")
    print("="*60 + "\n")
    
    return all_permits

def score_permit_ai(permit):
    """AI scoring algorithm"""
    value = permit.get('estimated_value', 0)
    if value >= 500000:
        size_score = 95
    elif value >= 250000:
        size_score = 80
    elif value >= 100000:
        size_score = 65
    else:
        size_score = 50
    
    address = str(permit.get('address', '')).lower()
    if 'nashville' in address or 'broadway' in address or 'downtown' in address:
        location_score = 90
    elif 'murfreesboro' in address or 'gallatin' in address or 'brentwood' in address:
        location_score = 75
    else:
        location_score = 60
    
    permit_type = str(permit.get('permit_type', '')).lower()
    if 'commercial' in permit_type or 'new construction' in permit_type:
        type_score = 85
    elif 'addition' in permit_type or 'renovation' in permit_type:
        type_score = 70
    else:
        type_score = 60
    
    urgency_score = 72  # Would use AI sentiment analysis in production
    
    total_score = (
        size_score * 0.35 +
        location_score * 0.25 +
        urgency_score * 0.20 +
        type_score * 0.20
    )
    
    permit['score'] = round(total_score, 1)
    permit['score_breakdown'] = {
        'size_score': size_score,
        'location_score': location_score,
        'urgency_score': urgency_score,
        'type_score': type_score
    }
    
    return permit

def generate_pdf_report(leads, date):
    """Generate PDF with real data"""
    buffer = io.BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=letter)
    elements = []
    styles = getSampleStyleSheet()
    
    title = Paragraph(f'<b>Top Contractor Leads - {date}</b>', styles['Heading1'])
    elements.append(title)
    elements.append(Spacer(1, 0.3*inch))
    
    for i, lead in enumerate(leads, 1):
        lead_title = Paragraph(f"<b>Lead #{i} - Score: {lead.get('score', 0)}/100</b>", styles['Heading2'])
        elements.append(lead_title)
        elements.append(Spacer(1, 0.1*inch))
        
        data = [
            ['County:', lead.get('county', 'N/A')],
            ['Address:', lead.get('address', 'N/A')],
            ['Permit Type:', lead.get('permit_type', 'N/A')],
            ['Value:', f"${lead.get('estimated_value', 0):,.2f}"],
            ['Permit #:', lead.get('permit_number', 'N/A')],
        ]
        
        table = Table(data, colWidths=[1.5*inch, 4.5*inch])
        table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (0, -1), colors.lightgrey),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        
        elements.append(table)
        elements.append(Spacer(1, 0.2*inch))
    
    doc.build(elements)
    buffer.seek(0)
    return buffer

# ==================== ROUTES ====================

@app.route('/')
def index():
    """Landing page"""
    return render_template('index.html')

@app.route('/live')
def live_scraper():
    """Live scraping dashboard"""
    return """
<!DOCTYPE html>
<html>
<head>
    <title>LIVE Scraper - Contractor Leads</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { 
            font-family: 'Segoe UI', sans-serif;
            background: #f5f5f5;
        }
        .navbar {
            background: linear-gradient(135deg, #1a5490 0%, #2d7ab8 100%);
            color: white;
            padding: 20px;
            text-align: center;
        }
        .banner {
            background: linear-gradient(135deg, #ff6b35 0%, #ff8c42 100%);
            color: white;
            padding: 20px;
            text-align: center;
            font-size: 18px;
            font-weight: bold;
        }
        .container {
            max-width: 1200px;
            margin: 40px auto;
            padding: 0 20px;
        }
        .control-panel {
            background: white;
            padding: 30px;
            border-radius: 10px;
            margin-bottom: 30px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .btn {
            display: inline-block;
            padding: 15px 30px;
            background: #ff6b35;
            color: white;
            text-decoration: none;
            border-radius: 5px;
            margin: 10px 10px 10px 0;
            font-weight: bold;
            border: none;
            cursor: pointer;
            font-size: 16px;
        }
        .btn:hover { background: #ff5520; }
        .btn-secondary {
            background: #1a5490;
        }
        .btn-secondary:hover { background: #153d6f; }
        #status {
            margin-top: 20px;
            padding: 15px;
            background: #f8f9fa;
            border-radius: 5px;
            font-family: monospace;
            white-space: pre-wrap;
            display: none;
        }
        #results {
            margin-top: 20px;
        }
        .lead-card {
            background: white;
            padding: 25px;
            border-radius: 10px;
            margin-bottom: 20px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            border-left: 5px solid #1a5490;
        }
        .lead-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 15px;
        }
        .lead-rank {
            font-size: 24px;
            font-weight: bold;
            color: #1a5490;
        }
        .lead-score {
            font-size: 32px;
            font-weight: bold;
            color: #ff6b35;
        }
        .lead-details {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 15px;
        }
        .detail-item {
            padding: 10px;
            background: #f8f9fa;
            border-radius: 5px;
        }
        .detail-label {
            font-size: 12px;
            color: #666;
            text-transform: uppercase;
            margin-bottom: 5px;
        }
        .detail-value {
            font-size: 16px;
            color: #333;
            font-weight: 600;
        }
        .loading {
            text-align: center;
            padding: 40px;
            font-size: 18px;
            color: #666;
        }
        .spinner {
            border: 4px solid #f3f3f3;
            border-top: 4px solid #1a5490;
            border-radius: 50%;
            width: 40px;
            height: 40px;
            animation: spin 1s linear infinite;
            margin: 20px auto;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
    </style>
</head>
<body>
    <div class="navbar">
        <h1>üï∑Ô∏è LIVE Web Scraper</h1>
        <p>Real-time permit data from Tennessee counties</p>
    </div>
    
    <div class="banner">
        ‚ö° LIVE MODE: Scraping REAL data from county websites RIGHT NOW!
    </div>
    
    <div class="container">
        <div class="control-panel">
            <h2>üéØ Scrape & Score Live Data</h2>
            <p style="margin: 15px 0; color: #666;">
                Click below to scrape real building permit data from county websites,
                score them with AI, and see the top leads.
            </p>
            
            <button class="btn" onclick="runScraper()">üöÄ Start Scraping Now</button>
            <button class="btn btn-secondary" onclick="window.location.href='/demo'">üìä View Demo Data</button>
            
            <div id="status"></div>
        </div>
        
        <div id="results"></div>
    </div>
    
    <script>
        function runScraper() {
            const statusDiv = document.getElementById('status');
            const resultsDiv = document.getElementById('results');
            
            statusDiv.style.display = 'block';
            statusDiv.innerHTML = '‚è≥ Scraping county websites...\\n';
            resultsDiv.innerHTML = '<div class="loading"><div class="spinner"></div><p>Fetching real data from county websites...</p></div>';
            
            fetch('/live/scrape')
                .then(response => response.json())
                .then(data => {
                    statusDiv.innerHTML += `‚úÖ Scraped ${data.total_permits} permits\\n`;
                    statusDiv.innerHTML += `ü§ñ Scored with AI\\n`;
                    statusDiv.innerHTML += `üìä Top ${data.top_leads.length} leads selected\\n`;
                    
                    let html = '';
                    data.top_leads.forEach((lead, i) => {
                        html += `
                            <div class="lead-card">
                                <div class="lead-header">
                                    <div class="lead-rank">#${i+1}</div>
                                    <div class="lead-score">${lead.score}/100</div>
                                </div>
                                <div class="lead-details">
                                    <div class="detail-item">
                                        <div class="detail-label">County</div>
                                        <div class="detail-value">${lead.county}</div>
                                    </div>
                                    <div class="detail-item">
                                        <div class="detail-label">Address</div>
                                        <div class="detail-value">${lead.address || 'N/A'}</div>
                                    </div>
                                    <div class="detail-item">
                                        <div class="detail-label">Permit Type</div>
                                        <div class="detail-value">${lead.permit_type || 'N/A'}</div>
                                    </div>
                                    <div class="detail-item">
                                        <div class="detail-label">Estimated Value</div>
                                        <div class="detail-value">$${lead.estimated_value.toLocaleString()}</div>
                                    </div>
                                    <div class="detail-item">
                                        <div class="detail-label">Data Source</div>
                                        <div class="detail-value" style="font-size: 0.9em; color: #666;">${lead.data_source || 'üìã Standard'}</div>
                                    </div>
                                    <div class="detail-item">
                                        <div class="detail-label">Permit Number</div>
                                        <div class="detail-value">${lead.permit_number || 'N/A'}</div>
                                    </div>
                                </div>
                                <div style="margin-top: 15px; padding-top: 15px; border-top: 1px solid #e0e0e0; font-size: 14px; color: #666;">
                                    <strong>AI Score Breakdown:</strong>
                                    Job Size: ${lead.score_breakdown.size_score}/100 | 
                                    Location: ${lead.score_breakdown.location_score}/100 | 
                                    Urgency: ${lead.score_breakdown.urgency_score}/100 | 
                                    Type: ${lead.score_breakdown.type_score}/100
                                </div>
                            </div>
                        `;
                    });
                    
                    resultsDiv.innerHTML = html;
                })
                .catch(error => {
                    statusDiv.innerHTML += `‚ùå Error: ${error}\\n`;
                    resultsDiv.innerHTML = '<div class="loading"><p style="color: red;">Error scraping data. Check console for details.</p></div>';
                });
        }
    </script>
</body>
</html>
    """

@app.route('/live/scrape')
def live_scrape():
    """API endpoint that actually scrapes live data"""
    try:
        # Scrape all counties
        permits = scrape_all_counties_live()
        
        # Score them
        scored = [score_permit_ai(p) for p in permits]
        scored.sort(key=lambda x: x['score'], reverse=True)
        
        # Top 10
        top_leads = scored[:10]
        
        return jsonify({
            'success': True,
            'total_permits': len(permits),
            'top_leads': top_leads,
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/live/pdf')
def live_pdf():
    """Generate PDF from live data"""
    permits = scrape_all_counties_live()
    scored = [score_permit_ai(p) for p in permits]
    scored.sort(key=lambda x: x['score'], reverse=True)
    top_leads = scored[:10]
    
    date = datetime.now().strftime('%Y-%m-%d')
    pdf = generate_pdf_report(top_leads, date)
    
    return send_file(
        pdf,
        mimetype='application/pdf',
        as_attachment=True,
        download_name=f'live_contractor_leads_{date}.pdf'
    )

if __name__ == '__main__':
    port = 5002
    print("\n" + "="*70)
    print("üï∑Ô∏è  CONTRACTOR LEADS - LIVE SCRAPER MODE")
    print("="*70)
    print(f"üåê Open in browser: http://localhost:{port}/live")
    print("="*70)
    print("\n‚ö° LIVE SCRAPING:")
    print("   ‚Ä¢ Pulls REAL data from county websites")
    print("   ‚Ä¢ Nashville: Uses open data API")
    print("   ‚Ä¢ Other counties: Sample data (implement real scrapers)")
    print("   ‚Ä¢ AI scoring in real-time")
    print("   ‚Ä¢ PDF generation from live data")
    print("\nüìñ Landing page: http://localhost:5002")
    print("üìä Live scraper: http://localhost:5002/live")
    print("="*70 + "\n")
    
    app.run(host='0.0.0.0', port=port, debug=True)
